{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/boston.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input features in order:\n",
    "1) CRIM: per capita crime rate by town\n",
    "2) ZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "3) INDUS: proportion of non-retail business acres per town\n",
    "4) CHAS: Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "5) NOX: nitric oxides concentration (parts per 10 million) [parts/10M]\n",
    "6) RM: average number of rooms per dwelling\n",
    "7) AGE: proportion of owner-occupied units built prior to 1940\n",
    "8) DIS: weighted distances to five Boston employment centres\n",
    "9) RAD: index of accessibility to radial highways\n",
    "10) TAX: full-value property-tax rate per $10,000 [$/10k]\n",
    "11) PTRATIO: pupil-teacher ratio by town\n",
    "12) B: The result of the equation B=1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "13) LSTAT: % lower status of the population\n",
    "\n",
    "Output variable:\n",
    "1) MEDV: Median value of owner-occupied homes in $1000's [k$]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the rows where MEDV is over 100 or under 0\n",
    "df = df[df['MEDV'] > dsfdsf]\n",
    "df = df[df['MEDV'] < dsfdsfdsf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HINT there is a function made just for this purpose\n",
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let y be the target column, and X be the rest of the df\n",
    "X = \n",
    "y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with x and y train sets\n",
    "model.fit(dsfdsf, dsfdsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predictions on the test set\n",
    "preds = model.predict(dsfdsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean square error for the predictions (a value to see the value of the predictions, lower is better)\n",
    "# find the error between the y_test and the preds\n",
    "mse = mean_squared_error(dsfdsfdsf, dsfdsfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"learning_rate\": [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    \"max_depth\": [3, 4, 5, 6, 8, 10, 12, 15],\n",
    "    \"min_child_weight\": [1, 3, 5, 7],\n",
    "    \"gamma\": [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "    \"colsample_bytree\": [0.3, 0.4, 0.5, 0.7],\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500, 900, 1100, 1500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ues the model and the params to create a random search\n",
    "random_search = RandomizedSearchCV(adsfdsfdsf, param_distributions=params, n_iter=1000, scoring=\"neg_mean_squared_error\", n_jobs=-1, cv=5)\n",
    "\n",
    "# fit the model with x and y train sets\n",
    "random_search.fit(adsfdsaf, adsfdsafadsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a new model based on the random search\n",
    "model_new = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new preductions with the new model\n",
    "preds = dsfdsfd.predict(dsfdsfdsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new mean square error\n",
    "mse_new = mean_squared_error(dsfdsf, dsfdsf)\n",
    "\n",
    "mse_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"relation between better error on the new model and the old error: {(mse_new / mse)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('intro-ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4e3c7c6ce170c226e8aab0029d1fe7db2eb67d8b78cdb8a5d7439fd4704886d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
